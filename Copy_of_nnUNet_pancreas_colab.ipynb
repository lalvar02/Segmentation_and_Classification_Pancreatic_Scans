{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalvar02/Segmentation_and_Classification_Pancreatic_Scans/blob/main/Copy_of_nnUNet_pancreas_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c48f7fd",
      "metadata": {
        "id": "4c48f7fd"
      },
      "source": [
        "# Pancreas Seg+Cls with nnUNetv2\n",
        "\n",
        "Generates a nnU-Net v2 model for pancreas segmentation and classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bbe5e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "76bbe5e0",
        "outputId": "061f0bdc-4022-416b-d8a6-84ec893765d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4009118025.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch, os, sys, subprocess\n",
        "!nvidia-smi\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7844197",
      "metadata": {
        "id": "f7844197"
      },
      "source": [
        "## Environment Setup & Imports\n",
        "This cell sets up the Python environment for nnU-Net training/inference and imports all required packages.\n",
        "\n",
        "**Purpose**:\n",
        "- Ensure `nnunetv2` is available in the environment.\n",
        "- Import PyTorch, NumPy, nnU-Net utilities, and other dependencies used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4364d8f7",
      "metadata": {
        "id": "4364d8f7"
      },
      "outputs": [],
      "source": [
        "!pip -q install --no-input nnunetv2 nibabel SimpleITK pandas==2.2.2 scikit-image --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11832d0f",
      "metadata": {
        "id": "11832d0f"
      },
      "source": [
        "\n",
        "## Dataset and Path Configuration\n",
        "This cell sets up the required folder setup for nnUNet configuration.\n",
        "\n",
        "- **Required folder layout**:\n",
        "```\n",
        "  working/\n",
        "    nnUNet_raw/\n",
        "      Dataset_name/  \n",
        "        images_Tr/\n",
        "        labelsTr/\n",
        "        images_Ts/\n",
        "    nnUNet_processed/\n",
        "      Dataset_name/\n",
        "    nnUNet_results/  \n",
        "      Dataset_name/    \n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5737780e-215a-44c6-e8cd-7ce1e45f6ed8",
        "id": "-46ERlSgsnTU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "RAW_DS_DIR: /content/drive/MyDrive/ColabData/working/nnUNet_raw/Dataset777_PancreasSegCls\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Change this to match your dataset mount point\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "INPUT_ROOT = \"/content/drive/MyDrive/ColabData\"\n",
        "\n",
        "# Create dataset folder structure\n",
        "DS_ID = 777  # arbitrary unused ID\n",
        "DATASET_NAME = f\"Dataset{DS_ID}_PancreasSegCls\"\n",
        "\n",
        "PLANS_NAME   = \"nnUNetResEncUNetMPlans\" # the same plans as training\n",
        "CONFIG       = \"3d_fullres\"             # or \"2d\" - must match how you trained\n",
        "TRAINER_NAME = \"TrainerSegCls\"          # your custom trainer class name used in training\n",
        "FOLD         = 0\n",
        "\n",
        "# nnU-Net v2 paths (local workspace inside Kaggle session)\n",
        "BASE = os.path.join(INPUT_ROOT, \"working\")\n",
        "os.environ[\"nnUNet_raw\"] = os.path.join(BASE, \"nnUNet_raw\")\n",
        "os.environ[\"nnUNet_preprocessed\"] = os.path.join(BASE, \"nnUNet_preprocessed\")\n",
        "os.environ[\"nnUNet_results\"] = os.path.join(BASE, \"nnUNet_results\")\n",
        "\n",
        "for k in (\"nnUNet_raw\", \"nnUNet_preprocessed\", \"nnUNet_results\"):\n",
        "    os.makedirs(os.environ[k], exist_ok=True)\n",
        "\n",
        "RAW_DS_DIR = os.path.join(os.environ[\"nnUNet_raw\"], DATASET_NAME)\n",
        "PREPRO_DS_DIR = os.path.join(os.environ[\"nnUNet_preprocessed\"], DATASET_NAME)\n",
        "RESULTS_DS_DIR = os.path.join(os.environ[\"nnUNet_results\"], DATASET_NAME)\n",
        "\n",
        "# for the training images and labels\n",
        "IMAGES_TR = imagesTr = os.path.join(RAW_DS_DIR, \"imagesTr\")\n",
        "LABELS_TR = labelsTr = os.path.join(RAW_DS_DIR, \"labelsTr\")\n",
        "# for the test images\n",
        "IMAGES_TS = imagesTs = os.path.join(RAW_DS_DIR, \"imagesTs\")\n",
        "# for the validation images and labels\n",
        "IMAGES_VAL = os.path.join(RAW_DS_DIR, \"imagesVal\")\n",
        "LABELS_VAL = os.path.join(RAW_DS_DIR, \"labelsVal\")\n",
        "for d in (IMAGES_TR, LABELS_TR, IMAGES_VAL, LABELS_VAL, IMAGES_TS):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"RAW_DS_DIR:\", RAW_DS_DIR)"
      ],
      "id": "-46ERlSgsnTU"
    },
    {
      "cell_type": "markdown",
      "id": "2cdead7d",
      "metadata": {
        "id": "2cdead7d"
      },
      "source": [
        "\n",
        "## Convert input data to nnU-Net v2 format\n",
        "\n",
        "- We copy **training** images into `imagesTr/` and labels into `labelsTr/`.\n",
        "- We copy **test** images into `imagesTs/`.\n",
        "- We keep validation images seperate\n",
        "- We generate a `dataset.json` with the right channels/labels and cases.\n",
        "- We also build a CSV mapping **case -> subtype** for the classification head.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87f2bb4-986d-4b5e-f1bd-237b82eb6d68",
        "id": "Wr3ssF4nswZt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /content/drive/MyDrive/ColabData/working/nnUNet_raw/Dataset777_PancreasSegCls/trainval_subtypes.csv with 288 rows\n",
            "dataset.json written.\n",
            "imagesTr: 288 labelsTr: 288 imagesTs: 72\n"
          ]
        }
      ],
      "source": [
        "import os, re, json, shutil, pandas as pd\n",
        "\n",
        "train_root = os.path.join(INPUT_ROOT, \"train\")\n",
        "val_root   = os.path.join(INPUT_ROOT, \"validation\")\n",
        "test_root  = os.path.join(INPUT_ROOT, \"test\")\n",
        "\n",
        "def cp(src, dst):\n",
        "    if not os.path.exists(dst):\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "# Collect train/val by subtype folders\n",
        "subtypes = [\"subtype0\", \"subtype1\", \"subtype2\"]\n",
        "train_cls_rows, val_cls_rows = [], []\n",
        "\n",
        "def process_split(split_root, out_img_dir, out_lbl_dir, cls_rows):\n",
        "    for st in subtypes:\n",
        "        st_dir = os.path.join(split_root, st)\n",
        "        if not os.path.isdir(st_dir):\n",
        "            continue\n",
        "        subtype_idx = int(st.replace(\"subtype\", \"\"))\n",
        "        for f in os.listdir(st_dir):\n",
        "            if not f.endswith(\"_0000.nii.gz\"):\n",
        "                continue\n",
        "            img_path = os.path.join(st_dir, f)\n",
        "            case_id  = f.replace(\"_0000.nii.gz\", \"\")           # e.g., quiz_0_041\n",
        "            lbl_path = os.path.join(st_dir, case_id + \".nii.gz\")\n",
        "            # copy image (keep _0000)\n",
        "            cp(img_path, os.path.join(out_img_dir, case_id + \"_0000.nii.gz\"))\n",
        "            # copy label if present (no channel suffix)\n",
        "            if os.path.exists(lbl_path):\n",
        "                cp(lbl_path, os.path.join(out_lbl_dir, case_id + \".nii.gz\"))\n",
        "            cls_rows.append({\"case\": case_id, \"subtype\": subtype_idx})\n",
        "\n",
        "# TRAIN → imagesTr/labelsTr\n",
        "process_split(train_root, IMAGES_TR, LABELS_TR, train_cls_rows)\n",
        "# VAL   → imagesVal/labelsVal  (NOT mixed into imagesTr/labelsTr)\n",
        "process_split(val_root,   IMAGES_VAL, LABELS_VAL, val_cls_rows)\n",
        "\n",
        "# TEST images → imagesTs (no labels)\n",
        "if os.path.isdir(test_root):\n",
        "    for f in os.listdir(test_root):\n",
        "        if f.endswith(\"_0000.nii.gz\"):\n",
        "            case_id = f[:-len(\"_0000.nii.gz\")]\n",
        "            cp(os.path.join(test_root, f), os.path.join(IMAGES_TS, case_id + \"_0000.nii.gz\"))\n",
        "\n",
        "# Write classification CSVs\n",
        "train_csv = os.path.join(RAW_DS_DIR, \"train_subtypes.csv\")\n",
        "val_csv   = os.path.join(RAW_DS_DIR, \"val_subtypes.csv\")\n",
        "both_csv  = os.path.join(RAW_DS_DIR, \"trainval_subtypes.csv\")  # for convenience if you need one file\n",
        "\n",
        "pd.DataFrame(train_cls_rows).drop_duplicates().to_csv(train_csv, index=False)\n",
        "pd.DataFrame(val_cls_rows).drop_duplicates().to_csv(val_csv, index=False)\n",
        "pd.concat([pd.DataFrame(train_cls_rows), pd.DataFrame(val_cls_rows)], ignore_index=True)\\\n",
        "  .drop_duplicates().to_csv(both_csv, index=False)\n",
        "\n",
        "print(\"Wrote:\", train_csv, \"rows:\", len(train_cls_rows))\n",
        "print(\"Wrote:\", val_csv,   \"rows:\", len(val_cls_rows))\n",
        "print(\"Wrote:\", both_csv)\n",
        "\n",
        "# Build dataset.json (TRAIN ONLY)\n",
        "training_list = [\n",
        "    {\"image\": f\"./imagesTr/{f}\", \"label\": f\"./labelsTr/{f.replace('_0000.nii.gz', '.nii.gz')}\"}\n",
        "    for f in sorted(os.listdir(IMAGES_TR)) if f.endswith(\"_0000.nii.gz\")\n",
        "]\n",
        "dataset_json = {\n",
        "    \"name\": \"PancreasSegCls\",\n",
        "    \"description\": \"Pancreas ROI segmentation (0 bg, 1 pancreas, 2 lesion) + subtype classification (0/1/2).\",\n",
        "    \"tensorImageSize\": \"3D\",\n",
        "    \"reference\": \"Local\",\n",
        "    \"licence\": \"CC-BY-NC\",\n",
        "    \"labels\": {\"background\": 0, \"pancreas\": 1, \"lesion\": 2},\n",
        "    \"modality\": {\"0\": \"CT\"},\n",
        "    \"channel_names\": {\"0\": \"CT\"},\n",
        "    \"numTraining\": len(training_list),\n",
        "    \"file_ending\": \".nii.gz\",\n",
        "    \"training\": training_list,  # ONLY train here\n",
        "    \"test\": [f\"./imagesTs/{f}\" for f in sorted(os.listdir(IMAGES_TS)) if f.endswith(\"_0000.nii.gz\")]\n",
        "}\n",
        "with open(os.path.join(RAW_DS_DIR, \"dataset.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset_json, f, indent=2)\n",
        "\n",
        "print(\"dataset.json written.\")\n",
        "print(\"Train:\", len(training_list),\n",
        "      \"imagesVal:\", len([x for x in os.listdir(IMAGES_VAL) if x.endswith('_0000.nii.gz')]),\n",
        "      \"labelsVal:\", len([x for x in os.listdir(LABELS_VAL) if x.endswith('.nii') or x.endswith('.nii.gz')]),\n",
        "      \"imagesTs:\", len([x for x in os.listdir(IMAGES_TS) if x.endswith('_0000.nii.gz')]))\n"
      ],
      "id": "Wr3ssF4nswZt"
    },
    {
      "cell_type": "markdown",
      "id": "oy6Nc8MvdY1b",
      "metadata": {
        "id": "oy6Nc8MvdY1b"
      },
      "source": [
        "## Label Sanitization for nnU-Net (force `{0,1,2}` and `uint8`)\n",
        "\n",
        "**Purpose**  \n",
        "This utility ensures that all segmentation label files in the `labelsTr` directory conform to nnU-Net’s expected format:\n",
        "- Only contain the class IDs `0`, `1`, and `2`.\n",
        "- Stored as `uint8` integer type rather than floating-point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b947b178-5b0a-42b5-a9e2-933a3e14a8c6",
        "id": "2Lz6_K0Bs8zY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanitization complete. Modified 288 file(s).\n",
            "Examples of changes:\n",
            "  01) quiz_0_041.nii.gz: [0.0, 1.0, 2.0] -> [0, 1, 2]\n",
            "  02) quiz_0_060.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  03) quiz_0_066.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  04) quiz_0_070.nii.gz: [0.0, 1.0, 2.0] -> [0, 1, 2]\n",
            "  05) quiz_0_077.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  06) quiz_0_117.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  07) quiz_0_126.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  08) quiz_0_139.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  09) quiz_0_145.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "  10) quiz_0_150.nii.gz: [0.0, 1.0000152587890625, 2.0] -> [0, 1, 2]\n",
            "\n",
            "Verification: 0 file(s) still have unexpected labels.\n"
          ]
        }
      ],
      "source": [
        "# --- Sanitize nnU-Net labels  --- #\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "LABELS_DIRS = [LABELS_TR, LABELS_VAL]  # sanitize both\n",
        "\n",
        "def snap_to_labels(arr, valid=(0.0, 1.0, 2.0)):\n",
        "    \"\"\"\n",
        "    Map any float-ish labels to the nearest of valid labels (0,1,2).\n",
        "    Returns uint8 array.\n",
        "    \"\"\"\n",
        "    arr = arr.astype(np.float32, copy=False)\n",
        "    diffs = np.stack([np.abs(arr - v) for v in valid], axis=0)  # [len(valid), ...]\n",
        "    snapped = np.argmin(diffs, axis=0).astype(np.uint8)         # 0/1/2\n",
        "    return snapped\n",
        "\n",
        "def sanitize_dir(LABELS_DIR):\n",
        "    assert os.path.isdir(LABELS_DIR), f\"Not found: {LABELS_DIR}\"\n",
        "    changed_files = []\n",
        "    issues = []\n",
        "\n",
        "    # accept both .nii.gz and .nii\n",
        "    label_files = [f for f in sorted(os.listdir(LABELS_DIR))\n",
        "                   if f.lower().endswith(\".nii.gz\") or f.lower().endswith(\".nii\")]\n",
        "\n",
        "    for fname in label_files:\n",
        "        fpath = os.path.join(LABELS_DIR, fname)\n",
        "        try:\n",
        "            img = nib.load(fpath)\n",
        "            data = img.get_fdata(dtype=np.float32)\n",
        "            uniq = np.unique(data)\n",
        "\n",
        "            # If already clean {0,1,2} and dtype is uint8, skip fast\n",
        "            already_clean = np.all(np.isin(uniq, [0.0, 1.0, 2.0])) and img.get_data_dtype() == np.uint8\n",
        "            if already_clean:\n",
        "                continue\n",
        "\n",
        "            # Snap + validate\n",
        "            snapped = snap_to_labels(data, valid=(0.0, 1.0, 2.0))\n",
        "            new_uniq = np.unique(snapped)\n",
        "            if not np.all(np.isin(new_uniq, [0, 1, 2])):\n",
        "                issues.append((fname, f\"Unexpected labels after snap: {new_uniq.tolist()}\"))\n",
        "                continue\n",
        "\n",
        "            # Backup once\n",
        "            bak = fpath + \".bak\"\n",
        "            if not os.path.exists(bak):\n",
        "                shutil.copy2(fpath, bak)\n",
        "\n",
        "            # Preserve affine & header; store as uint8\n",
        "            hdr = img.header.copy()\n",
        "            hdr.set_data_dtype(np.uint8)\n",
        "            out_img = nib.Nifti1Image(snapped, img.affine, header=hdr)\n",
        "            nib.save(out_img, fpath)\n",
        "\n",
        "            changed_files.append((fname, uniq.tolist(), new_uniq.tolist()))\n",
        "        except Exception as e:\n",
        "            issues.append((fname, f\"ERROR: {e}\"))\n",
        "\n",
        "    # Reporting\n",
        "    print(f\"\\n[{LABELS_DIR}] Sanitization complete. Modified {len(changed_files)} file(s).\")\n",
        "    if changed_files:\n",
        "        print(\"Examples of changes:\")\n",
        "        for i, (fn, before, after) in enumerate(changed_files[:10], 1):\n",
        "            print(f\"  {i:02d}) {fn}: {before} -> {after}\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"\\nWarnings/Issues:\")\n",
        "        for it in issues[:20]:\n",
        "            print(\" \", it)\n",
        "        if len(issues) > 20:\n",
        "            print(f\"  ... ({len(issues)-20} more)\")\n",
        "\n",
        "    # Verification pass\n",
        "    bad = []\n",
        "    for fname in label_files:\n",
        "        try:\n",
        "            data = nib.load(os.path.join(LABELS_DIR, fname)).get_fdata(dtype=np.float32)\n",
        "            uniq = np.unique(data)\n",
        "            if not np.all(np.isin(uniq, [0.0, 1.0, 2.0])):\n",
        "                bad.append((fname, uniq.tolist()))\n",
        "        except Exception as e:\n",
        "            bad.append((fname, f\"ERROR reading: {e}\"))\n",
        "    print(f\"Verification: {len(bad)} file(s) still have unexpected labels.\")\n",
        "    if bad[:10]:\n",
        "        print(\" First few:\", bad[:10])\n",
        "\n",
        "    return {\"changed\": changed_files, \"issues\": issues, \"bad\": bad}\n",
        "\n",
        "# Run on both labelsTr and labelsVal\n",
        "overall = {\"changed\": 0, \"issues\": 0, \"bad\": 0}\n",
        "for d in LABELS_DIRS:\n",
        "    if d and os.path.isdir(d):\n",
        "        res = sanitize_dir(d)\n",
        "        overall[\"changed\"] += len(res[\"changed\"])\n",
        "        overall[\"issues\"]  += len(res[\"issues\"])\n",
        "        overall[\"bad\"]     += len(res[\"bad\"])\n",
        "    else:\n",
        "        print(f\"\\n[skip] Not found: {d}\")\n",
        "\n",
        "print(\"\\n=== Overall summary ===\")\n",
        "print(\"Total modified files:\", overall[\"changed\"])\n",
        "print(\"Total issues:\", overall[\"issues\"])\n",
        "print(\"Total remaining bad:\", overall[\"bad\"])\n"
      ],
      "id": "2Lz6_K0Bs8zY"
    },
    {
      "cell_type": "markdown",
      "id": "5d4e516a",
      "metadata": {
        "id": "5d4e516a"
      },
      "source": [
        "\n",
        "## Custom Trainer: add a classification head\n",
        "\n",
        "- Wrap the ResEnc M network and attach a **global pooling + linear** head for 3-way subtype logits.\n",
        "- Compute **segmentation loss** (Dice+CE, default) + **classification CE** (with weight `cls_lambda`).  \n",
        "- We obtain the **subtype target** by reading `trainval_subtypes.csv` using the case name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8173dcf-ef40-4572-8e7e-0d026314e043",
        "id": "KBBfDg4_yU4G"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/custom_trainer_cls.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/custom_trainer_cls.py\n",
        "# save as custom_trainer_cls.py\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Dict, Any, List, Tuple, Union\n",
        "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
        "from nnunetv2.training.loss.dice import get_tp_fp_fn_tn\n",
        "from nnunetv2.utilities.helpers import dummy_context\n",
        "from torch import autocast\n",
        "\n",
        "class GlobalPoolHead(nn.Module):\n",
        "    def __init__(self, in_ch: int, n_classes: int = 3):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc = nn.Linear(in_ch, n_classes)\n",
        "\n",
        "    def forward(self, feat: torch.Tensor) -> torch.Tensor:\n",
        "        # Accept [N,C,H,W] (2D) or [N,C,D,H,W] (3D)\n",
        "        if feat.dim() == 5:\n",
        "            x = F.adaptive_avg_pool3d(feat, 1).flatten(1)  # [N,C,1,1,1] -> [N,C]\n",
        "        elif feat.dim() == 4:\n",
        "            x = F.adaptive_avg_pool2d(feat, 1).flatten(1)  # [N,C,1,1]   -> [N,C]\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected feature rank {feat.dim()}, expected 4 or 5\")\n",
        "        return self.fc(x)\n",
        "\n",
        "class TrainerSegCls(nnUNetTrainer):\n",
        "    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict,\n",
        "                 device: torch.device = torch.device(\"cuda\")):\n",
        "        super().__init__(plans, configuration, fold, dataset_json, device)\n",
        "        self.classifier_head: nn.Module = None\n",
        "        self._cached_bottleneck: torch.Tensor | None = None\n",
        "        self.ce_cls = nn.CrossEntropyLoss()\n",
        "        self.cls_lambda = 0.5          # or read from env; see note below\n",
        "        self.case_to_subtype = {}      # fill in initialize() (CSV) or pass via env\n",
        "\n",
        "        # To spped up training during debug\n",
        "        #self.num_epochs = 2\n",
        "        #self.enable_deep_supervision = False  # optional: faster\n",
        "        #self.save_every = 0\n",
        "\n",
        "    def initialize(self):\n",
        "        # build network, optimizer, dataloaders, loss, etc.\n",
        "        super().initialize()\n",
        "\n",
        "        # discover encoder bottleneck channels\n",
        "        if hasattr(self.network, \"encoder\") and hasattr(self.network.encoder, \"stages\"):\n",
        "            last_stage = self._plain_network().encoder.stages[-1]\n",
        "            ch = None\n",
        "            for attr in (\"output_channels\", \"out_channels\", \"num_features\"):\n",
        "                if hasattr(last_stage, attr):\n",
        "                    ch = int(getattr(last_stage, attr))\n",
        "                    break\n",
        "            if ch is None and hasattr(last_stage, \"convs\") and last_stage.convs:\n",
        "                ch = int(last_stage.convs[-1].out_channels)\n",
        "            if ch is None:\n",
        "                # robust fallback for ResEnc M\n",
        "                ch = 320\n",
        "        else:\n",
        "            raise RuntimeError(\"Unexpected nnU-Net network structure: encoder/stages not found.\")\n",
        "\n",
        "        # classification head\n",
        "        self.classifier_head = GlobalPoolHead(ch, n_classes=3).to(self.device)\n",
        "\n",
        "        # hook to cache bottleneck tensor on forward\n",
        "        def _save_bottleneck(module, inp, out):\n",
        "            t = out\n",
        "            # some stages return tuples/lists; pick the last Tensor inside\n",
        "            while isinstance(t, (list, tuple)):\n",
        "                t = t[-1]\n",
        "            if not isinstance(t, torch.Tensor):\n",
        "                raise RuntimeError(f\"Encoder hook returned non-tensor: {type(t)}\")\n",
        "            self._cached_bottleneck = t\n",
        "        self._hook_handle = last_stage.register_forward_hook(_save_bottleneck)\n",
        "\n",
        "        # (optional) env-driven config for your CSV + lambda\n",
        "        import os, pandas as pd\n",
        "        self.cls_lambda = float(os.environ.get(\"CLS_LAMBDA\", self.cls_lambda))\n",
        "        csv_path = os.environ.get(\"CASE_TO_SUBTYPE_CSV\", \"\")\n",
        "        if os.path.isfile(csv_path):\n",
        "            df = pd.read_csv(csv_path)\n",
        "            self.case_to_subtype = {str(r[\"case\"]): int(r[\"subtype\"]) for _, r in df.iterrows()}\n",
        "        else:\n",
        "            print(\"[TrainerSegCls] WARNING: xxxx_subtypes.csv not found. Using zeros for cls labels.\")\n",
        "\n",
        "        self._best_ckpt_mtime = None  # track when checkpoint_best.pth last changed\n",
        "\n",
        "        # Resume cls head if available\n",
        "        latest_head = os.path.join(self.output_folder, \"cls_head_latest.pth\")\n",
        "        if os.path.isfile(latest_head):\n",
        "            try:\n",
        "                self.classifier_head.load_state_dict(\n",
        "                    torch.load(latest_head, map_location=self.device), strict=False\n",
        "                )\n",
        "                print(f\"[TrainerSegCls] Loaded classification head from {latest_head}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[TrainerSegCls] WARNING: could not load {latest_head}: {e}\")\n",
        "\n",
        "    # unwrapping helper (recommended if you use torch.compile or DDP)\n",
        "    def _plain_network(self):\n",
        "        net = self.network\n",
        "        if hasattr(net, \"module\"):  # DDP\n",
        "            net = net.module\n",
        "        try:\n",
        "            from torch._dynamo import OptimizedModule\n",
        "            if isinstance(net, OptimizedModule):  # torch.compile\n",
        "                net = net._orig_mod\n",
        "        except Exception:\n",
        "            pass\n",
        "        return net\n",
        "\n",
        "    def _cls_targets_from_keys(self, keys, device, batch_size=None):\n",
        "        # Normalize to a plain Python list of strings\n",
        "        ks = []\n",
        "        if keys is None:\n",
        "            ks = []\n",
        "        else:\n",
        "            try:\n",
        "                import numpy as np\n",
        "                ks = np.array(keys).ravel().tolist()  # handles list/tuple/np.array scalars\n",
        "            except Exception:\n",
        "                ks = list(keys) if isinstance(keys, (list, tuple)) else [keys]\n",
        "\n",
        "        # Map to integer subtypes (default 0 if missing)\n",
        "        targets_list = [int(self.case_to_subtype.get(str(k), 0)) for k in ks]\n",
        "\n",
        "        # If we still have a length mismatch (or empty), build a safe fallback of zeros\n",
        "        if batch_size is not None and len(targets_list) != batch_size:\n",
        "            targets_list = [0] * batch_size\n",
        "\n",
        "        return torch.as_tensor(targets_list, device=device, dtype=torch.long)\n",
        "\n",
        "    def train_step(self, batch: dict) -> dict:\n",
        "        data, target = batch['data'], batch['target']\n",
        "        data = data.to(self.device, non_blocking=True)\n",
        "        if isinstance(target, list):\n",
        "            target = [i.to(self.device, non_blocking=True) for i in target]\n",
        "        else:\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "        self.optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(self.device.type, enabled=True) if self.device.type == 'cuda' else dummy_context():\n",
        "            seg_logits = self.network(data)             # triggers our hook\n",
        "            feat = self._cached_bottleneck if self._cached_bottleneck is not None else \\\n",
        "                (seg_logits[0] if isinstance(seg_logits, (list, tuple)) else seg_logits)\n",
        "            cls_logits = self.classifier_head(feat)\n",
        "\n",
        "            seg_loss = self.loss(seg_logits, target)    # keep base seg loss unchanged\n",
        "            N = cls_logits.shape[0]\n",
        "            cls_target = self._cls_targets_from_keys(batch.get('keys', None), cls_logits.device, batch_size=N)\n",
        "            cls_loss = self.ce_cls(cls_logits, cls_target)\n",
        "            l = seg_loss + self.cls_lambda * cls_loss\n",
        "\n",
        "        if self.grad_scaler is not None:\n",
        "            self.grad_scaler.scale(l).backward()\n",
        "            self.grad_scaler.unscale_(self.optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
        "            self.grad_scaler.step(self.optimizer)\n",
        "            self.grad_scaler.update()\n",
        "        else:\n",
        "            l.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
        "            self.optimizer.step()\n",
        "        return {'loss': l.detach().cpu().numpy()}\n",
        "\n",
        "    def validation_step(self, batch: dict) -> dict:\n",
        "        data, target = batch['data'], batch['target']\n",
        "        data = data.to(self.device, non_blocking=True)\n",
        "        if isinstance(target, list):\n",
        "            target = [i.to(self.device, non_blocking=True) for i in target]\n",
        "        else:\n",
        "            target = target.to(self.device, non_blocking=True)\n",
        "\n",
        "        # Autocast can be annoying\n",
        "        # If the device_type is 'cpu' then it's slow as heck and needs to be disabled.\n",
        "        # If the device_type is 'mps' then it will complain that mps is not implemented, even if enabled=False is set. Whyyyyyyy. (this is why we don't make use of enabled=False)\n",
        "        # So autocast will only be active if we have a cuda device.\n",
        "        with autocast(self.device.type, enabled=True) if self.device.type == 'cuda' else dummy_context():\n",
        "            seg_logits = self.network(data)\n",
        "            feat = self._cached_bottleneck if self._cached_bottleneck is not None else \\\n",
        "                (seg_logits[0] if isinstance(seg_logits, (list, tuple)) else seg_logits)\n",
        "            cls_logits = self.classifier_head(feat)\n",
        "\n",
        "            seg_loss = self.loss(seg_logits, target)\n",
        "            N = cls_logits.shape[0]\n",
        "            cls_target = self._cls_targets_from_keys(batch.get('keys', None), cls_logits.device, batch_size=N)\n",
        "            cls_loss = self.ce_cls(cls_logits, cls_target)\n",
        "            l = seg_loss + self.cls_lambda * cls_loss\n",
        "\n",
        "        # used for Dice calculation and validation logging\n",
        "        output = seg_logits\n",
        "\n",
        "        # we only need the output with the highest output resolution (if DS enabled)\n",
        "        if self.enable_deep_supervision:\n",
        "            output = output[0]\n",
        "            target = target[0]\n",
        "\n",
        "        # the following is needed for online evaluation. Fake dice (green line)\n",
        "        axes = [0] + list(range(2, output.ndim))\n",
        "\n",
        "        if self.label_manager.has_regions:\n",
        "            predicted_segmentation_onehot = (torch.sigmoid(output) > 0.5).long()\n",
        "        else:\n",
        "            # no need for softmax\n",
        "            output_seg = output.argmax(1)[:, None]\n",
        "            predicted_segmentation_onehot = torch.zeros(output.shape, device=output.device, dtype=torch.float32)\n",
        "            predicted_segmentation_onehot.scatter_(1, output_seg, 1)\n",
        "            del output_seg\n",
        "\n",
        "        if self.label_manager.has_ignore_label:\n",
        "            if not self.label_manager.has_regions:\n",
        "                mask = (target != self.label_manager.ignore_label).float()\n",
        "                # CAREFUL that you don't rely on target after this line!\n",
        "                target[target == self.label_manager.ignore_label] = 0\n",
        "            else:\n",
        "                if target.dtype == torch.bool:\n",
        "                    mask = ~target[:, -1:]\n",
        "                else:\n",
        "                    mask = 1 - target[:, -1:]\n",
        "                # CAREFUL that you don't rely on target after this line!\n",
        "                target = target[:, :-1]\n",
        "        else:\n",
        "            mask = None\n",
        "\n",
        "        tp, fp, fn, _ = get_tp_fp_fn_tn(predicted_segmentation_onehot, target, axes=axes, mask=mask)\n",
        "\n",
        "        tp_hard = tp.detach().cpu().numpy()\n",
        "        fp_hard = fp.detach().cpu().numpy()\n",
        "        fn_hard = fn.detach().cpu().numpy()\n",
        "        if not self.label_manager.has_regions:\n",
        "            # [1:] in order to remove background\n",
        "            tp_hard = tp_hard[1:]\n",
        "            fp_hard = fp_hard[1:]\n",
        "            fn_hard = fn_hard[1:]\n",
        "\n",
        "        return {'loss': l.detach().cpu().numpy(), 'tp_hard': tp_hard, 'fp_hard': fp_hard, 'fn_hard': fn_hard}\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Let nnU-Net do its normal bookkeeping & checkpointing first\n",
        "        super().on_epoch_end()\n",
        "\n",
        "        # 1) Always save the latest cls head\n",
        "        latest_head = os.path.join(self.output_folder, \"cls_head_latest.pth\")\n",
        "        torch.save(self.classifier_head.state_dict(), latest_head)\n",
        "\n",
        "        # 2) If the best checkpoint has been updated this epoch, mirror a best head\n",
        "        best_ckpt = os.path.join(self.output_folder, \"checkpoint_best.pth\")\n",
        "        if os.path.isfile(best_ckpt):\n",
        "            mtime = os.path.getmtime(best_ckpt)\n",
        "            if self._best_ckpt_mtime is None or mtime > self._best_ckpt_mtime:\n",
        "                best_head = os.path.join(self.output_folder, \"cls_head_best.pth\")\n",
        "                torch.save(self.classifier_head.state_dict(), best_head)\n",
        "                self._best_ckpt_mtime = mtime\n",
        "                print(f\"[TrainerSegCls] Saved best classification head → {best_head}\")\n",
        "\n",
        "    def on_train_end(self):\n",
        "        # Call parent to write checkpoint_final etc.\n",
        "        super().on_train_end()\n",
        "        final_head = os.path.join(self.output_folder, \"cls_head_final.pth\")\n",
        "        torch.save(self.classifier_head.state_dict(), final_head)\n",
        "        print(f\"[TrainerSegCls] Saved final classification head → {final_head}\")\n"
      ],
      "id": "KBBfDg4_yU4G"
    },
    {
      "cell_type": "markdown",
      "id": "r4jtIUbNwF_6",
      "metadata": {
        "id": "r4jtIUbNwF_6"
      },
      "source": [
        "## Register Custom Trainer so `-tr TrainerSegCls` Works\n",
        "\n",
        "**Purpose**  \n",
        "Make your custom trainer class discoverable by nnU-Net’s CLI (`nnUNetv2_train` / `nnUNetv2_predict`) so you can call it with `-tr TrainerSegCls`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCcYONqRnGs_",
        "outputId": "15577ef0-9d7a-4349-db26-91cba066c0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom trainer registered at: /usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/trainer_segcls.py\n",
            "You can now use: -tr TrainerSegCls\n"
          ]
        }
      ],
      "source": [
        "# Register custom trainer inside nnUNet so -tr TrainerSegCls works\n",
        "import os, shutil, pathlib, sys, textwrap, importlib\n",
        "\n",
        "import nnunetv2\n",
        "pkg_dir = pathlib.Path(nnunetv2.__file__).parent\n",
        "trainer_pkg = pkg_dir / \"training\" / \"nnUNetTrainer\"\n",
        "trainer_pkg.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "src = \"/content/custom_trainer_cls.py\"  # <-- this is where you wrote it earlier\n",
        "dst = trainer_pkg / \"trainer_segcls.py\"\n",
        "assert os.path.exists(src), f\"Custom trainer not found at {src}.\"\n",
        "shutil.copy2(src, dst)\n",
        "\n",
        "init_py = trainer_pkg / \"__init__.py\"\n",
        "if not init_py.exists():\n",
        "    init_py.write_text(\"\")\n",
        "with open(init_py, \"a\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\nfrom .trainer_segcls import TrainerSegCls\\n\")\n",
        "\n",
        "importlib.invalidate_caches()\n",
        "print(\"Custom trainer registered at:\", dst)\n",
        "print(\"You can now use: -tr TrainerSegCls\")\n"
      ],
      "id": "kCcYONqRnGs_"
    },
    {
      "cell_type": "markdown",
      "id": "670d00f8",
      "metadata": {
        "id": "670d00f8"
      },
      "source": [
        "## Plan & Preprocess the Dataset (nnU-Net v2)\n",
        "\n",
        "This cell runs nnU-Net’s **planning + preprocessing** step for your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae0fca0",
      "metadata": {
        "id": "5ae0fca0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# K80-friendly: use 3d_fullres; small patch size will be auto-determined by nnU-Net v2\n",
        "!nnUNetv2_plan_and_preprocess -d {DS_ID} -pl nnUNetPlannerResEncM --verify_dataset_integrity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VVv6-Dljv5tZ",
      "metadata": {
        "id": "VVv6-Dljv5tZ"
      },
      "source": [
        "In case we need to update the plan without preprocessing the data again\n",
        "\n",
        "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md#point_right-we-recommend-nnu-net-resenc-l-as-the-new-default-nnu-net-configuration-point_left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PDmEh2EfsVl1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDmEh2EfsVl1",
        "outputId": "a29813ad-1383-4f7e-8749-e574116030af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59.  117.  180.5], 3d_lowres: [59, 117, 180]\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 134, 'patch_size': (np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([117. , 180.5]), 'spacing': array([0.73242188, 0.73242188]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([ 59. , 117. , 180.5]), 'spacing': array([2.        , 0.73242188, 0.73242188]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/drive/MyDrive/ColabData/working/nnUNet_preprocessed/Dataset777_PancreasSegCls/nnUNetResEncUNetMPlans.json\n"
          ]
        }
      ],
      "source": [
        "!nnUNetv2_plan_experiment -d {DS_ID} -pl nnUNetPlannerResEncM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f338a60d",
      "metadata": {
        "id": "f338a60d"
      },
      "source": [
        "## Launch Training (Custom Trainer)\n",
        "\n",
        "**Purpose**  \n",
        "Configure runtime parameters for your **custom nnU-Net v2 trainer** and start a training run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install nnU-Net v2 and dependencies\n",
        "!pip install nnunetv2 nibabel simpleitk --quiet\n",
        "\n",
        "# Set nnU-Net environment variables\n",
        "import os\n",
        "os.environ[\"nnUNet_raw\"] = \"/content/drive/MyDrive/ColabData/working/nnUNet_raw\"\n",
        "os.environ[\"nnUNet_preprocessed\"] = \"/content/drive/MyDrive/ColabData/working/nnUNet_preprocessed\"\n",
        "os.environ[\"nnUNet_results\"] = \"/content/drive/MyDrive/ColabData/working/nnUNet_results\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeTsILdDBhut",
        "outputId": "5a733e2a-2b61-452d-fd95-0452cf10c092"
      },
      "id": "JeTsILdDBhut",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5842545",
        "outputId": "8d9eb32c-ffe8-495f-8d8a-a50ebed49984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...\n",
            "2025-08-15 18:10:23.207594: Using torch.compile...\n",
            "[TrainerSegCls] TRAIN with CE weights: [1.3548387289047241, 0.7924528121948242, 1.0]\n",
            "2025-08-15 18:10:25.581164: do_dummy_2d_data_aug: False\n",
            "2025-08-15 18:10:25.599903: Using splits from existing split file: /content/drive/MyDrive/ColabData/working/nnUNet_preprocessed/Dataset777_PancreasSegCls/splits_final.json\n",
            "2025-08-15 18:10:25.610543: The split file contains 5 splits.\n",
            "2025-08-15 18:10:25.613472: Desired fold for training: 0\n",
            "2025-08-15 18:10:25.622649: This split has 201 training and 51 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 192], 'median_image_size_in_voxels': [59.0, 118.0, 181.0], 'spacing': [2.0, 0.73046875, 0.73046875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset777_PancreasSegCls', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [2.0, 0.73046875, 0.73046875], 'original_median_shape_after_transp': [64, 119, 178], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1929.0, 'mean': 74.89175415039062, 'median': 78.01163482666016, 'min': -319.0, 'percentile_00_5': -55.99610900878906, 'percentile_99_5': 179.97802734375, 'std': 44.09819793701172}}} \n",
            "\n",
            "2025-08-15 18:10:37.009556: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2025-08-15 18:10:37.082008: \n",
            "2025-08-15 18:10:37.087375: Epoch 0\n",
            "2025-08-15 18:10:37.092413: Current learning rate: 0.01\n",
            "W0815 18:11:10.830000 7311 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "2025-08-15 18:18:07.444075: train_loss 1.2928\n",
            "2025-08-15 18:18:07.456455: val_loss 1.0457\n",
            "2025-08-15 18:18:07.460411: Pseudo dice [np.float32(0.0), np.float32(0.0)]\n",
            "2025-08-15 18:18:07.463317: Epoch time: 450.37 s\n",
            "2025-08-15 18:18:07.467193: Yayy! New best EMA pseudo Dice: 0.0\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:18:17.059325: \n",
            "2025-08-15 18:18:17.062378: Epoch 1\n",
            "2025-08-15 18:18:17.070013: Current learning rate: 0.00999\n",
            "2025-08-15 18:22:29.057664: train_loss 1.0468\n",
            "2025-08-15 18:22:29.064780: val_loss 0.9593\n",
            "2025-08-15 18:22:29.069065: Pseudo dice [np.float32(0.4055), np.float32(0.0)]\n",
            "2025-08-15 18:22:29.072505: Epoch time: 252.0 s\n",
            "2025-08-15 18:22:29.076664: Yayy! New best EMA pseudo Dice: 0.0203000009059906\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:22:35.076742: \n",
            "2025-08-15 18:22:35.081065: Epoch 2\n",
            "2025-08-15 18:22:35.084277: Current learning rate: 0.00998\n",
            "2025-08-15 18:27:11.887395: train_loss 0.8698\n",
            "2025-08-15 18:27:11.893249: val_loss 0.8227\n",
            "2025-08-15 18:27:11.896818: Pseudo dice [np.float32(0.5295), np.float32(0.2607)]\n",
            "2025-08-15 18:27:11.905522: Epoch time: 276.82 s\n",
            "2025-08-15 18:27:11.913776: Yayy! New best EMA pseudo Dice: 0.05779999867081642\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:27:22.721754: \n",
            "2025-08-15 18:27:22.725773: Epoch 3\n",
            "2025-08-15 18:27:22.730204: Current learning rate: 0.00997\n",
            "2025-08-15 18:31:52.338106: train_loss 0.7564\n",
            "2025-08-15 18:31:52.341538: val_loss 0.7693\n",
            "2025-08-15 18:31:52.344167: Pseudo dice [np.float32(0.6325), np.float32(0.3435)]\n",
            "2025-08-15 18:31:52.346929: Epoch time: 269.62 s\n",
            "2025-08-15 18:31:52.349794: Yayy! New best EMA pseudo Dice: 0.10080000013113022\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:31:57.528237: \n",
            "2025-08-15 18:31:57.532358: Epoch 4\n",
            "2025-08-15 18:31:57.535020: Current learning rate: 0.00996\n",
            "2025-08-15 18:36:08.211824: train_loss 0.6695\n",
            "2025-08-15 18:36:08.219979: val_loss 0.7535\n",
            "2025-08-15 18:36:08.225587: Pseudo dice [np.float32(0.6198), np.float32(0.4176)]\n",
            "2025-08-15 18:36:08.228858: Epoch time: 250.69 s\n",
            "2025-08-15 18:36:08.232636: Yayy! New best EMA pseudo Dice: 0.14259999990463257\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:36:14.126142: \n",
            "2025-08-15 18:36:14.129321: Epoch 5\n",
            "2025-08-15 18:36:14.132026: Current learning rate: 0.00995\n",
            "2025-08-15 18:40:41.530796: train_loss 0.616\n",
            "2025-08-15 18:40:41.542344: val_loss 0.6431\n",
            "2025-08-15 18:40:41.550830: Pseudo dice [np.float32(0.7024), np.float32(0.3814)]\n",
            "2025-08-15 18:40:41.560916: Epoch time: 267.41 s\n",
            "2025-08-15 18:40:41.570094: Yayy! New best EMA pseudo Dice: 0.18250000476837158\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:40:54.154387: \n",
            "2025-08-15 18:40:54.157863: Epoch 6\n",
            "2025-08-15 18:40:54.160983: Current learning rate: 0.00995\n",
            "2025-08-15 18:45:31.860119: train_loss 0.603\n",
            "2025-08-15 18:45:31.874830: val_loss 0.6372\n",
            "2025-08-15 18:45:31.877873: Pseudo dice [np.float32(0.6979), np.float32(0.4571)]\n",
            "2025-08-15 18:45:31.886456: Epoch time: 277.71 s\n",
            "2025-08-15 18:45:31.901107: Yayy! New best EMA pseudo Dice: 0.22200000286102295\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:45:47.093133: \n",
            "2025-08-15 18:45:47.099797: Epoch 7\n",
            "2025-08-15 18:45:47.106459: Current learning rate: 0.00994\n",
            "2025-08-15 18:50:21.448220: train_loss 0.5592\n",
            "2025-08-15 18:50:21.458506: val_loss 0.5862\n",
            "2025-08-15 18:50:21.463204: Pseudo dice [np.float32(0.7461), np.float32(0.376)]\n",
            "2025-08-15 18:50:21.466945: Epoch time: 274.36 s\n",
            "2025-08-15 18:50:21.471497: Yayy! New best EMA pseudo Dice: 0.25589999556541443\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:50:30.916584: \n",
            "2025-08-15 18:50:30.919702: Epoch 8\n",
            "2025-08-15 18:50:30.923838: Current learning rate: 0.00993\n",
            "2025-08-15 18:55:03.416875: train_loss 0.5706\n",
            "2025-08-15 18:55:03.423966: val_loss 0.6742\n",
            "2025-08-15 18:55:03.430058: Pseudo dice [np.float32(0.7322), np.float32(0.4964)]\n",
            "2025-08-15 18:55:03.434016: Epoch time: 272.5 s\n",
            "2025-08-15 18:55:03.439074: Yayy! New best EMA pseudo Dice: 0.29170000553131104\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:55:15.622524: \n",
            "2025-08-15 18:55:15.629335: Epoch 9\n",
            "2025-08-15 18:55:15.635723: Current learning rate: 0.00992\n",
            "2025-08-15 18:59:47.794518: train_loss 0.5838\n",
            "2025-08-15 18:59:47.798784: val_loss 0.5904\n",
            "2025-08-15 18:59:47.802555: Pseudo dice [np.float32(0.7444), np.float32(0.5221)]\n",
            "2025-08-15 18:59:47.810452: Epoch time: 272.18 s\n",
            "2025-08-15 18:59:47.814611: Yayy! New best EMA pseudo Dice: 0.32589998841285706\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 18:59:56.646247: \n",
            "2025-08-15 18:59:56.649417: Epoch 10\n",
            "2025-08-15 18:59:56.652013: Current learning rate: 0.00991\n",
            "2025-08-15 19:04:29.248043: train_loss 0.5759\n",
            "2025-08-15 19:04:29.252077: val_loss 0.6105\n",
            "2025-08-15 19:04:29.254905: Pseudo dice [np.float32(0.7558), np.float32(0.528)]\n",
            "2025-08-15 19:04:29.257617: Epoch time: 272.61 s\n",
            "2025-08-15 19:04:29.260584: Yayy! New best EMA pseudo Dice: 0.35749998688697815\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:04:40.319664: \n",
            "2025-08-15 19:04:40.324193: Epoch 11\n",
            "2025-08-15 19:04:40.327907: Current learning rate: 0.0099\n",
            "2025-08-15 19:09:13.122538: train_loss 0.476\n",
            "2025-08-15 19:09:13.128884: val_loss 0.4996\n",
            "2025-08-15 19:09:13.131904: Pseudo dice [np.float32(0.784), np.float32(0.5363)]\n",
            "2025-08-15 19:09:13.133691: Epoch time: 272.81 s\n",
            "2025-08-15 19:09:13.135419: Yayy! New best EMA pseudo Dice: 0.387800008058548\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:09:18.738491: \n",
            "2025-08-15 19:09:18.747221: Epoch 12\n",
            "2025-08-15 19:09:18.751063: Current learning rate: 0.00989\n",
            "2025-08-15 19:13:56.352992: train_loss 0.5034\n",
            "2025-08-15 19:13:56.371552: val_loss 0.5273\n",
            "2025-08-15 19:13:56.386077: Pseudo dice [np.float32(0.771), np.float32(0.5598)]\n",
            "2025-08-15 19:13:56.400327: Epoch time: 277.62 s\n",
            "2025-08-15 19:13:56.406141: Yayy! New best EMA pseudo Dice: 0.4154999852180481\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:14:04.694568: \n",
            "2025-08-15 19:14:04.697518: Epoch 13\n",
            "2025-08-15 19:14:04.700065: Current learning rate: 0.00988\n",
            "2025-08-15 19:18:30.067498: train_loss 0.4534\n",
            "2025-08-15 19:18:30.071780: val_loss 0.5376\n",
            "2025-08-15 19:18:30.074935: Pseudo dice [np.float32(0.7666), np.float32(0.4901)]\n",
            "2025-08-15 19:18:30.079688: Epoch time: 265.38 s\n",
            "2025-08-15 19:18:30.084636: Yayy! New best EMA pseudo Dice: 0.4368000030517578\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:18:39.781139: \n",
            "2025-08-15 19:18:39.786165: Epoch 14\n",
            "2025-08-15 19:18:39.790664: Current learning rate: 0.00987\n",
            "2025-08-15 19:23:08.841053: train_loss 0.4638\n",
            "2025-08-15 19:23:08.845259: val_loss 0.5124\n",
            "2025-08-15 19:23:08.848144: Pseudo dice [np.float32(0.7629), np.float32(0.557)]\n",
            "2025-08-15 19:23:08.851896: Epoch time: 269.07 s\n",
            "2025-08-15 19:23:08.854521: Yayy! New best EMA pseudo Dice: 0.45910000801086426\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:23:16.658391: \n",
            "2025-08-15 19:23:16.661931: Epoch 15\n",
            "2025-08-15 19:23:16.665218: Current learning rate: 0.00986\n",
            "2025-08-15 19:27:42.586531: train_loss 0.4418\n",
            "2025-08-15 19:27:42.591210: val_loss 0.5982\n",
            "2025-08-15 19:27:42.598448: Pseudo dice [np.float32(0.7891), np.float32(0.5927)]\n",
            "2025-08-15 19:27:42.604820: Epoch time: 265.93 s\n",
            "2025-08-15 19:27:42.611483: Yayy! New best EMA pseudo Dice: 0.4823000133037567\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:27:55.096374: \n",
            "2025-08-15 19:27:55.100241: Epoch 16\n",
            "2025-08-15 19:27:55.103869: Current learning rate: 0.00986\n",
            "2025-08-15 19:32:23.325895: train_loss 0.4537\n",
            "2025-08-15 19:32:23.335346: val_loss 0.5277\n",
            "2025-08-15 19:32:23.341607: Pseudo dice [np.float32(0.7843), np.float32(0.5958)]\n",
            "2025-08-15 19:32:23.345219: Epoch time: 268.23 s\n",
            "2025-08-15 19:32:23.350774: Yayy! New best EMA pseudo Dice: 0.5030999779701233\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:32:34.024257: \n",
            "2025-08-15 19:32:34.027589: Epoch 17\n",
            "2025-08-15 19:32:34.031516: Current learning rate: 0.00985\n",
            "2025-08-15 19:36:55.896669: train_loss 0.3722\n",
            "2025-08-15 19:36:55.904879: val_loss 0.4762\n",
            "2025-08-15 19:36:55.908722: Pseudo dice [np.float32(0.756), np.float32(0.5035)]\n",
            "2025-08-15 19:36:55.912688: Epoch time: 261.88 s\n",
            "2025-08-15 19:36:55.916173: Yayy! New best EMA pseudo Dice: 0.5156999826431274\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:37:06.501689: \n",
            "2025-08-15 19:37:06.504970: Epoch 18\n",
            "2025-08-15 19:37:06.508827: Current learning rate: 0.00984\n",
            "2025-08-15 19:41:26.639471: train_loss 0.3754\n",
            "2025-08-15 19:41:26.660288: val_loss 0.5913\n",
            "2025-08-15 19:41:26.682438: Pseudo dice [np.float32(0.7329), np.float32(0.422)]\n",
            "2025-08-15 19:41:26.703575: Epoch time: 260.14 s\n",
            "2025-08-15 19:41:26.749790: Yayy! New best EMA pseudo Dice: 0.5218999981880188\n",
            "[TrainerSegCls] Saved best classification head → /content/drive/MyDrive/ColabData/working/nnUNet_results/Dataset777_PancreasSegCls/TrainerSegCls__nnUNetResEncUNetMPlans__3d_fullres/fold_0/cls_head_best.pth\n",
            "2025-08-15 19:41:39.515156: \n",
            "2025-08-15 19:41:39.527934: Epoch 19\n",
            "2025-08-15 19:41:39.531215: Current learning rate: 0.00983\n",
            "2025-08-15 19:45:56.318877: train_loss 0.498\n",
            "2025-08-15 19:45:56.345445: val_loss 0.8071\n",
            "2025-08-15 19:45:56.376652: Pseudo dice [np.float32(0.7808), np.float32(0.2618)]\n",
            "2025-08-15 19:45:56.380734: Epoch time: 256.81 s\n",
            "2025-08-15 19:46:00.948405: \n",
            "2025-08-15 19:46:00.957396: Epoch 20\n",
            "2025-08-15 19:46:00.961174: Current learning rate: 0.00982\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Register our custom trainer class via PYTHONPATH\n",
        "import sys\n",
        "sys.path.append(\"/content\")\n",
        "\n",
        "# Set environment variables for nnU-Net v2 custom trainer\n",
        "os.environ[\"CASE_TO_SUBTYPE_CSV\"] = os.path.join(RAW_DS_DIR, \"train_subtypes.csv\")\n",
        "os.environ[\"CLS_LAMBDA\"] = \"0.3\"\n",
        "\n",
        "# To prevent multithreading errors in Windows\n",
        "# os.environ[\"nnUNet_n_proc_DA\"] = \"0\"\n",
        "\n",
        "# For clearer error messages while debugging\n",
        "# os.environ[\"nnUNet_compile\"] = \"0\"\n",
        "\n",
        "# Train 3d_fullres -tr TrainerSegCls\n",
        "!nnUNetv2_train {DS_ID} 3d_fullres 0 -tr TrainerSegCls -p nnUNetResEncUNetMPlans --npz --c\n"
      ],
      "id": "f5842545"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_SlqbJBwNQt"
      },
      "source": [
        "## Inference on test set\n",
        "- Predict segmentations using **nnUNetv2_predict**\n",
        "- Predict classification using **nnUNetPredictor**"
      ],
      "id": "z_SlqbJBwNQt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict segmentations\n",
        "MODEL_BASE   = os.path.join(RESULTS_DS_DIR, f\"{TRAINER_NAME}__{PLANS_NAME}__{CONFIG}\")\n",
        "MODEL_FOLD   = os.path.join(MODEL_BASE, f\"fold_{FOLD}\")\n",
        "\n",
        "PRED_DIR = os.path.join(MODEL_FOLD, \"predictions\")  # where you want the CSV saved (can reuse PRED_DIR)\n",
        "os.makedirs(PRED_DIR, exist_ok=True)\n",
        "\n",
        "# To prevent multithreading errors in Windows\n",
        "# os.environ[\"nnUNet_n_proc_DA\"] = \"0\"\n",
        "\n",
        "# -tr custom_trainer_cls.TrainerSegCls\n",
        "!nnUNetv2_predict -i {IMAGES_VAL} -o {PRED_DIR} -d {DS_ID} -c 3d_fullres -f 0 -tr TrainerSegCls -p nnUNetResEncUNetMPlans --disable_tta --save_probabilities\n",
        "\n",
        "# Evaluate the results to get the summary.json with Dice scores\n",
        "!nnUNetv2_evaluate_simple {LABELS_VAL} {PRED_DIR} -l 1 2"
      ],
      "metadata": {
        "id": "40mQY_p7wUZ1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "40mQY_p7wUZ1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgm6hY8wwcU3"
      },
      "outputs": [],
      "source": [
        "# Predict classification\n",
        "\n",
        "MODEL_BASE   = os.path.join(RESULTS_DS_DIR, f\"{TRAINER_NAME}__{PLANS_NAME}__{CONFIG}\")\n",
        "MODEL_FOLD   = os.path.join(MODEL_BASE, f\"fold_{FOLD}\")\n",
        "\n",
        "TEST_DIR     = IMAGES_VAL  # same as IMAGES_TS above (contains quiz_XXX_0000.nii.gz)\n",
        "# If you saved the head weights during training, point to them here (recommended):\n",
        "CLS_HEAD_WEIGHTS = f\"{MODEL_FOLD}/cls_head_best.pth\"\n",
        "\n",
        "import os, json, glob, csv, warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from nnunetv2.paths import nnUNet_results\n",
        "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "from nnunetv2.utilities.get_network_from_plans import get_network_from_plans\n",
        "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
        "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
        "from batchgenerators.utilities.file_and_folder_operations import join, maybe_mkdir_p\n",
        "\n",
        "# use same results tree that training created\n",
        "CKPT         = join(MODEL_FOLD, \"checkpoint_best.pth\")\n",
        "if not os.path.isfile(CKPT):\n",
        "    CKPT = join(MODEL_FOLD, \"checkpoint_final.pth\")\n",
        "assert os.path.isfile(CKPT), f\"Model checkpoint not found: {CKPT}\"\n",
        "\n",
        "plans_json_path   = join(MODEL_BASE, \"plans.json\")\n",
        "dataset_json_path = join(MODEL_BASE, \"dataset.json\")\n",
        "assert os.path.isfile(plans_json_path) and os.path.isfile(dataset_json_path), \"plans.json/dataset.json missing in model folder\"\n",
        "\n",
        "plans_dict   = json.load(open(plans_json_path, \"r\"))\n",
        "dataset_json = json.load(open(dataset_json_path, \"r\"))\n",
        "\n",
        "plans_manager      = PlansManager(plans_dict)\n",
        "configuration_mgr  = plans_manager.get_configuration(CONFIG)\n",
        "label_manager      = plans_manager.get_label_manager(dataset_json)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Use nnUNetPredictor only to do preprocessing & sliding-window — we do NOT export segmentations here\n",
        "predictor = nnUNetPredictor(\n",
        "    tile_step_size=0.5,\n",
        "    use_gaussian=True,\n",
        "    use_mirroring=True,\n",
        "    perform_everything_on_device=True,\n",
        "    device=device,\n",
        "    verbose=False,\n",
        "    verbose_preprocessing=False,\n",
        "    allow_tqdm=False\n",
        ")\n",
        "# Make sure MODEL_BASE points at: .../nnUNet_results/DATASET_NAME/TRAINER__PLANS__CONFIG\n",
        "# and CKPT is \"checkpoint_best.pth\" or \"checkpoint_final.pth\" in fold_{FOLD}\n",
        "predictor.initialize_from_trained_model_folder(\n",
        "    model_training_output_dir=MODEL_BASE,\n",
        "    use_folds=(FOLD,),\n",
        "    checkpoint_name=os.path.basename(CKPT),  # e.g. \"checkpoint_best.pth\"\n",
        ")\n",
        "\n",
        "# Build the segmentation net exactly like training (we’ll only use its encoder features)\n",
        "num_input_channels  = 1  # CT single-channel; adjust if you trained multi-channel\n",
        "num_output_channels = label_manager.num_segmentation_heads\n",
        "\n",
        "predictor.network.to(device)\n",
        "\n",
        "# Load seg weights (so encoder features match training)\n",
        "ckpt = torch.load(CKPT, map_location=device, weights_only=False)\n",
        "new_state = {}\n",
        "for k, v in ckpt['network_weights'].items():\n",
        "    key = k[7:] if k.startswith(\"module.\") and not next(iter(predictor.network.state_dict())).startswith(\"module.\") else k\n",
        "    new_state[key] = v\n",
        "missing, unexpected = predictor.network.load_state_dict(new_state, strict=False)\n",
        "if missing:    warnings.warn(f\"Missing seg keys: {missing[:10]}{'...' if len(missing)>10 else ''}\")\n",
        "if unexpected: warnings.warn(f\"Unexpected seg keys: {unexpected[:10]}{'...' if len(unexpected)>10 else ''}\")\n",
        "\n",
        "# Classification head (dimension-agnostic) — LazyLinear infers in_features on first call\n",
        "class GlobalPoolHead(nn.Module):\n",
        "    def __init__(self, n_classes: int = 3):\n",
        "        super().__init__()\n",
        "        self.fc = nn.LazyLinear(n_classes)\n",
        "    def forward(self, feat: torch.Tensor) -> torch.Tensor:\n",
        "        if feat.dim() == 5:\n",
        "            x = F.adaptive_avg_pool3d(feat, 1).flatten(1)\n",
        "        elif feat.dim() == 4:\n",
        "            x = F.adaptive_avg_pool2d(feat, 1).flatten(1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected feature rank {feat.dim()} (expected 4 or 5)\")\n",
        "        return self.fc(x)\n",
        "\n",
        "cls_head = GlobalPoolHead(n_classes=3).to(device)\n",
        "if CLS_HEAD_WEIGHTS and os.path.isfile(CLS_HEAD_WEIGHTS):\n",
        "    try:\n",
        "        cls_sd = torch.load(CLS_HEAD_WEIGHTS, map_location=device)\n",
        "        cls_head.load_state_dict(cls_sd, strict=False)\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Could not load classification head weights: {e}\\nProceeding with random init.\")\n",
        "else:\n",
        "    warnings.warn(\"Classification head weights not found; proceeding with random init (predictions will be unreliable).\")\n",
        "\n",
        "# Attach a hook on the last encoder stage to collect logits for each sliding-window patch\n",
        "_cached_logits = []\n",
        "def _bottleneck_to_logits(module, inp, out):\n",
        "    t = out\n",
        "    while isinstance(t, (list, tuple)):\n",
        "        t = t[-1]\n",
        "    if isinstance(t, torch.Tensor):\n",
        "        with torch.no_grad():\n",
        "            _cached_logits.append(cls_head(t).detach())  # [B, 3]\n",
        "\n",
        "enc_last = predictor.network.encoder.stages[-1]\n",
        "hook_handle = enc_last.register_forward_hook(_bottleneck_to_logits)\n",
        "\n",
        "maybe_mkdir_p(PRED_DIR)\n",
        "nii_ext = dataset_json.get(\"file_ending\", \".nii.gz\")\n",
        "\n",
        "test_imgs = sorted(glob.glob(os.path.join(TEST_DIR, \"*_0000.nii.gz\")))\n",
        "assert len(test_imgs) > 0, f\"No test images found in {TEST_DIR}\"\n",
        "\n",
        "csv_path = os.path.join(PRED_DIR, \"subtype_results.csv\")\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Names\", \"Subtype\"])\n",
        "\n",
        "    for img_path in test_imgs:\n",
        "        case_id = os.path.basename(img_path).replace(\"_0000.nii.gz\", \"\")  # quiz_XXX\n",
        "        # reset aggregator\n",
        "        _cached_logits.clear()\n",
        "\n",
        "        # Preprocess + sliding window forward (this fills _cached_logits via hook)\n",
        "        with torch.no_grad():\n",
        "            img_np, props = SimpleITKIO().read_images([img_path])  # props include spacing, etc.\n",
        "            # This internally preprocesses then calls the same sliding-window logic.\n",
        "            _ = predictor.predict_single_npy_array(img_np, props, None, None, False)\n",
        "\n",
        "        # Aggregate classification logits over all windows → case-level class\n",
        "        if len(_cached_logits) == 0:\n",
        "            warnings.warn(f\"No classification logits captured for {case_id}; defaulting to 0\")\n",
        "            subtype = 0\n",
        "        else:\n",
        "            case_logits = torch.cat(_cached_logits, dim=0).mean(dim=0)  # [3]\n",
        "            subtype = int(case_logits.argmax().item())\n",
        "\n",
        "        writer.writerow([f\"{case_id}{nii_ext}\", subtype])\n",
        "\n",
        "print(f\"Wrote CSV: {csv_path}\")\n"
      ],
      "id": "sgm6hY8wwcU3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**\n",
        "\n",
        "*   Segmentation\n",
        "    - DSC scores for whole pancreas & lesion\n",
        "\n",
        "*   Classification\n",
        "    - Macro-average F1 score"
      ],
      "metadata": {
        "id": "NyWQV7XCtqRB"
      },
      "id": "NyWQV7XCtqRB"
    },
    {
      "cell_type": "code",
      "source": [
        "## --------- Calculate DSC scores ---------- ##\n",
        "import os, re, json, numpy as np\n",
        "import SimpleITK as sitk  # pip install SimpleITK if missing\n",
        "\n",
        "LESION_LABEL = 2\n",
        "\n",
        "def strip_case(p):\n",
        "    b = os.path.basename(p)\n",
        "    b = re.sub(r\"\\.nii(\\.gz)?$\", \"\", b, flags=re.I)\n",
        "    b = re.sub(r\"_[0-9]{4}$\", \"\", b)  # drop _0000\n",
        "    return b\n",
        "\n",
        "def read_nii(p):\n",
        "    img = sitk.ReadImage(p)\n",
        "    return sitk.GetArrayFromImage(img)\n",
        "\n",
        "def dice_bin(pred, gt, eps=1e-6):\n",
        "    pred = pred.astype(bool); gt = gt.astype(bool)\n",
        "    tp = np.logical_and(pred, gt).sum(dtype=np.int64)\n",
        "    fp = np.logical_and(pred, ~gt).sum(dtype=np.int64)\n",
        "    fn = np.logical_and(~pred, gt).sum(dtype=np.int64)\n",
        "    return float((2*tp + eps) / (2*tp + fp + fn + eps))\n",
        "\n",
        "# Build GT <-> Pred pairs (by case id)\n",
        "gt_files = [f for f in os.listdir(LABELS_VAL) if f.endswith((\".nii\",\".nii.gz\"))]\n",
        "pairs, missing = [], []\n",
        "for f in gt_files:\n",
        "    cid = strip_case(f)\n",
        "    pred = None\n",
        "    for pf in os.listdir(PRED_DIR):\n",
        "        if pf.endswith((\".nii\",\".nii.gz\")) and strip_case(pf) == cid:\n",
        "            pred = os.path.join(PRED_DIR, pf); break\n",
        "    if pred is None:\n",
        "        missing.append(cid)\n",
        "    else:\n",
        "        pairs.append((os.path.join(LABELS_VAL, f), pred))\n",
        "\n",
        "whole, les_all, les_pos = [], [], []\n",
        "for gt_p, pr_p in pairs:\n",
        "    gt = read_nii(gt_p); pr = read_nii(pr_p)\n",
        "    if gt.shape != pr.shape:\n",
        "        raise ValueError(f\"Shape mismatch for {os.path.basename(gt_p)}: GT {gt.shape} vs PRED {pr.shape}\")\n",
        "    # Whole-pancreas = union(1,2) -> label > 0\n",
        "    whole.append(dice_bin(pr > 0, gt > 0))\n",
        "    # Lesion = label 2\n",
        "    gL, pL = (gt == LESION_LABEL), (pr == LESION_LABEL)\n",
        "    dL = dice_bin(pL, gL)\n",
        "    les_all.append(dL)\n",
        "    if gL.any(): les_pos.append(dL)\n",
        "\n",
        "print(\"n_eval =\", len(pairs), \" | n_missing =\", len(missing))\n",
        "if missing: print(\"Missing examples:\", missing[:10], \"...\")\n",
        "print(f\"Whole-pancreas DSC (mean): {np.mean(whole):.4f}\")\n",
        "print(f\"Lesion DSC (mean; lesion-positive cases): {np.mean(les_pos) if les_pos else float('nan'):.4f}\")\n",
        "print(f\"Lesion DSC (mean; across all cases): {np.mean(les_all):.4f}\")\n"
      ],
      "metadata": {
        "id": "EnVpdl6RET1a"
      },
      "execution_count": null,
      "outputs": [],
      "id": "EnVpdl6RET1a"
    },
    {
      "cell_type": "code",
      "source": [
        "## --------- Calculate macro-average F1 score ---------- ##\n",
        "import csv, os, re, json\n",
        "from collections import OrderedDict\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# === CONFIG: set these two paths ===\n",
        "PRED_CSV = os.path.join(PRED_DIR, \"subtype_results.csv\")\n",
        "GT_CSV   = os.path.join(RAW_DS_DIR, \"val_subtypes.csv\")\n",
        "\n",
        "# (optional) If you want to restrict to exactly the validation IDs:\n",
        "VAL_IDS = None  # e.g., ['quiz_0_168', 'quiz_0_041', ...] or load from splits_final.json\n",
        "\n",
        "def strip_case(name: str) -> str:\n",
        "    b = os.path.basename(str(name))\n",
        "    b = re.sub(r\"\\.nii(\\.gz)?$\", \"\", b, flags=re.I)  # drop .nii/.nii.gz\n",
        "    b = re.sub(r\"_[0-9]{4}$\", \"\", b)                 # drop _0000, if present\n",
        "    return b\n",
        "\n",
        "def read_csv_dict(path: str):\n",
        "    with open(path, \"r\", newline=\"\") as f:\n",
        "        return list(csv.DictReader(f))\n",
        "\n",
        "def get_col(row: dict, prefs):\n",
        "    for k in prefs:\n",
        "        if k in row: return row[k]\n",
        "    raise KeyError(f\"Expected one of columns {prefs}, got {list(row.keys())}\")\n",
        "\n",
        "# load predictions: Names, Subtype\n",
        "pred_rows = read_csv_dict(PRED_CSV)\n",
        "pred_map = OrderedDict()\n",
        "for r in pred_rows:\n",
        "    name = strip_case(get_col(r, (\"Names\",\"Name\",\"case\",\"Case\",\"id\",\"ID\")))\n",
        "    lab  = int(get_col(r, (\"Subtype\",\"subtype\",\"label\",\"Label\",\"class\",\"Class\")))\n",
        "    pred_map[name] = lab\n",
        "\n",
        "# load ground truth: case, subtype\n",
        "gt_rows = read_csv_dict(GT_CSV)\n",
        "gt_map = OrderedDict()\n",
        "for r in gt_rows:\n",
        "    name = strip_case(get_col(r, (\"case\",\"Case\",\"Names\",\"Name\",\"id\",\"ID\")))\n",
        "    lab  = int(get_col(r, (\"subtype\",\"Subtype\",\"label\",\"Label\",\"class\",\"Class\")))\n",
        "    gt_map[name] = lab\n",
        "\n",
        "# intersection (optionally filter to VAL_IDS)\n",
        "common = set(pred_map.keys()) & set(gt_map.keys())\n",
        "if VAL_IDS is not None:\n",
        "    common &= set(map(str, VAL_IDS))\n",
        "common = sorted(common)\n",
        "\n",
        "if not common:\n",
        "    raise RuntimeError(\"No overlapping case IDs between PRED_CSV and GT_CSV. Check filenames/columns.\")\n",
        "\n",
        "y_true = [gt_map[k] for k in common]\n",
        "y_pred = [pred_map[k] for k in common]\n",
        "\n",
        "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "print(f\"Macro-average F1 (3 classes) on {len(common)} cases: {macro_f1:.4f}\")\n",
        "\n",
        "# (nice to have) per-class and confusion matrix\n",
        "print(\"\\nPer-class report:\\n\", classification_report(y_true, y_pred, digits=3))\n",
        "print(\"Confusion matrix (labels in order):\", sorted(set(y_true) | set(y_pred)))\n",
        "print(confusion_matrix(y_true, y_pred, labels=sorted(set(y_true) | set(y_pred))))\n"
      ],
      "metadata": {
        "id": "O6aHnO7LZvqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "213fc594-9412-463d-b6d8-262e715c4f66"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PRED_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1689779920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# === CONFIG: set these two paths ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mPRED_CSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRED_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subtype_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mGT_CSV\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_DS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_subtypes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PRED_DIR' is not defined"
          ]
        }
      ],
      "id": "O6aHnO7LZvqg"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}